{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5599062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import glob\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.applications import DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecf31a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '2023sumdpl302m/devset_images/devset_images/'\n",
    "\n",
    "image_width = 224\n",
    "image_height = 224\n",
    "\n",
    "# Load the CSV file with image IDs and labels\n",
    "csv_file = pd.read_csv('2023sumdpl302m/devset_images_gt.csv')\n",
    "image_ids = csv_file['id'].values\n",
    "labels = csv_file['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85c3828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "y = []\n",
    "\n",
    "# Load and preprocess images\n",
    "for image_id, label in zip(image_ids, labels):\n",
    "    # Search for files with multiple extensions\n",
    "    image_path = os.path.join(dataset_path, f'{image_id}.jpg')\n",
    "    if not os.path.isfile(image_path):\n",
    "        image_path = os.path.join(dataset_path, f'{image_id}.png')\n",
    "        if not os.path.isfile(image_path):\n",
    "            image_path = os.path.join(dataset_path, f'{image_id}.gif')\n",
    "\n",
    "    if os.path.isfile(image_path):\n",
    "        # Load the image using OpenCV\n",
    "        try:\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        except:\n",
    "            # Retry with PNG extension\n",
    "            image_path = image_path[:-4] + '.png'\n",
    "            try:\n",
    "                image = cv2.imread(image_path)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "            except:\n",
    "                print(f\"Image not found: {image_path}\")\n",
    "                continue\n",
    "\n",
    "        # Resize the image to a fixed size\n",
    "        image = cv2.resize(image, (image_width, image_height))\n",
    "        image = image.astype('float32') / 255.0  # Normalize pixel values between 0 and 1\n",
    "\n",
    "        images.append(image)\n",
    "        y.append(label)\n",
    "    else:\n",
    "        print(f\"File not found: {image_path}\")\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "X = np.array(images)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726c9963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,  # Randomly rotate the images by up to 20 degrees\n",
    "    width_shift_range=0.1,  # Randomly shift the images horizontally by up to 10% of the width\n",
    "    height_shift_range=0.1,  # Randomly shift the images vertically by up to 10% of the height\n",
    "    zoom_range=0.2,  # Randomly zoom the images by up to 20%\n",
    "    horizontal_flip=True  # Randomly flip the images horizontally\n",
    ")\n",
    "\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(image_width, image_height, 3))\n",
    "\n",
    "# Freeze the weights of the pretrained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers on top of the pretrained base model\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
    "                    epochs=20,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# Retrieve the best epoch\n",
    "best_epoch = early_stopping.stopped_epoch + 1\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63146df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test set\n",
    "testset_path = '/2023sumdpl302m/test.csv'\n",
    "testset_images_folder = '/2023sumdpl302m/testset_images/testset_images'\n",
    "\n",
    "# Read the CSV file\n",
    "testset_data = pd.read_csv(testset_path)\n",
    "\n",
    "# Get the image IDs\n",
    "test_image_ids = testset_data['image_id'].values\n",
    "\n",
    "# Prepare empty lists for storing test images and predicted labels\n",
    "test_images = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Prepare empty lists for storing skipped image IDs\n",
    "skipped_images = []\n",
    "\n",
    "# Process each image\n",
    "for image_id in test_image_ids:\n",
    "    # Construct the image path\n",
    "    image_path = os.path.join(testset_images_folder, str(image_id))\n",
    "\n",
    "    # Check if the image path has an extension\n",
    "    if not any(image_path.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif']):\n",
    "        image_path += '.jpg'  # Add the default extension '.jpg'\n",
    "\n",
    "    # Load the image using OpenCV\n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    except:\n",
    "        # Retry with PNG extension\n",
    "        image_path = image_path[:-4] + '.png'\n",
    "        try:\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        except:\n",
    "            print(f\"Image not found: {image_path}\")\n",
    "            skipped_images.append(image_id)  # Add the skipped image ID to the list\n",
    "            continue\n",
    "\n",
    "    # Resize the image to a fixed size\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    image = image.astype('float32') / 255.0  # Normalize pixel values between 0 and 1\n",
    "\n",
    "    # Append the image to the list\n",
    "    test_images.append(image)\n",
    "\n",
    "    # Predict label for the image\n",
    "    prediction = model.predict(np.expand_dims(image, axis=0))\n",
    "    predicted_label = int(np.round(prediction)[0])\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Create a DataFrame for the predicted labels and image IDs\n",
    "predicted_df = pd.DataFrame({'id': test_image_ids, 'label': predicted_labels})\n",
    "\n",
    "# Print the predicted DataFrame\n",
    "print(predicted_df)\n",
    "\n",
    "# Print the skipped images\n",
    "print(\"Skipped Images:\")\n",
    "for image_id in skipped_images:\n",
    "    print(f'Image ID: {image_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b75dd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df.to_csv('test3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
